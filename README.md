# RatCortex-IOS
Home page of RatCortex-IOS dataset sharing.

# A Rat Cortex Video Segmentation Dataset for Intrinsic Optical Signal Tracking and Neural Activity Analysis
From MixLab, SIAT, ShenZhen, China.

# Abstract
Intrinsic optical signal imaging (IOSI) enables non-invasive monitoring of neural activity in the rat cortex, yet quantitative analysis remains hindered by low signal intensity, complex spatiotemporal patterns, and the lack of standardized benchmarks. To tackle this challenge, we present RatCortex-IOS â€“ a novel open-access video segmentation dataset specifically designed for standardizing IOS analysis in awake rodent models. Meanwhile, we implement an efficient processing pipeline leveraging foundation models to ensure annotation consistency while minimizing manual intervention. The dataset supports quantitative characterization of neural activation parameters including signal propagation velocity and cortical response topography, serving as a critical benchmark for developing automated analysis tools. Furthermore, this resource facilitates technique development in neuroimaging studies and accelerates the integration of computational approaches in IOS-based neuroscience research.

![image](https://github.com/user-attachments/assets/e7051764-a77b-4441-b27f-ef00323b4ef8)

Fig. 1 Data processing framework. Overall, raw data undergoes preprocessing and subsequent processing via the SAM2 model to generate our dataset. Preprocessing includes averaging, differential processing, and pseudo-color transformation steps, which convert massive raw grayscale images (indistinguishable to the naked eye) into visually interpretable color-coded signal maps while reducing data volume by two orders of magnitude. The processed image sequences are imported into an annotation tool, where a preloaded SAM model enables manual or automated annotation of prompts for the initial frames. A single-click inference operation then generates annotations for all frames. The annotated data is used for downstream tasks such as signal analysis and tracking. 


![image](https://github.com/user-attachments/assets/20f0c5ea-c2f5-4298-8f9e-5457194fb658)

Fig. 4 illustrates representative results, displaying six evenly spaced frames from a 26-frame propagation sequence. The visualization integrates trajectory and average velocity vectors and the complete results are in the attachment. These results have been confirmed by neuroscience experts to be consistent with the characteristics of real cortical signals, verifying the effectiveness of our method.

 



Due to original data are in TB level, we will upload part of the proccessed dataset in figshare, https://doi.org/10.6084/m9.figshare.28601813.v4.
If you are interested in the dataset, for more details please email: zhangwang@siat.ac.cn .
